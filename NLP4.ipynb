{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Mvw_J5z5UWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('weather_prediction_dataset.csv')"
      ],
      "metadata": {
        "id": "hZ23VwNN3xh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "RZ6QlSMh3_mc",
        "outputId": "b1320a38-96ba-4078-b37a-4139a7c1a9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          DATE  MONTH  BASEL_cloud_cover  BASEL_humidity  BASEL_pressure  \\\n",
              "0     20000101      1                  8            0.89          1.0286   \n",
              "1     20000102      1                  8            0.87          1.0318   \n",
              "2     20000103      1                  5            0.81          1.0314   \n",
              "3     20000104      1                  7            0.79          1.0262   \n",
              "4     20000105      1                  5            0.90          1.0246   \n",
              "...        ...    ...                ...             ...             ...   \n",
              "3649  20091228     12                  7            0.82          1.0084   \n",
              "3650  20091229     12                  7            0.92          1.0028   \n",
              "3651  20091230     12                  8            0.92          0.9979   \n",
              "3652  20091231     12                  7            0.93          0.9958   \n",
              "3653  20100101      1                  8            0.93          0.9965   \n",
              "\n",
              "      BASEL_global_radiation  BASEL_precipitation  BASEL_sunshine  \\\n",
              "0                       0.20                 0.03             0.0   \n",
              "1                       0.25                 0.00             0.0   \n",
              "2                       0.50                 0.00             3.7   \n",
              "3                       0.63                 0.35             6.9   \n",
              "4                       0.51                 0.07             3.7   \n",
              "...                      ...                  ...             ...   \n",
              "3649                    0.28                 0.42             0.3   \n",
              "3650                    0.22                 1.68             0.2   \n",
              "3651                    0.07                 1.54             0.0   \n",
              "3652                    0.17                 0.57             0.1   \n",
              "3653                    0.08                 0.56             0.0   \n",
              "\n",
              "      BASEL_temp_mean  BASEL_temp_min  ...  STOCKHOLM_temp_min  \\\n",
              "0                 2.9             1.6  ...                -9.3   \n",
              "1                 3.6             2.7  ...                 0.5   \n",
              "2                 2.2             0.1  ...                -1.0   \n",
              "3                 3.9             0.5  ...                 2.5   \n",
              "4                 6.0             3.8  ...                -1.8   \n",
              "...               ...             ...  ...                 ...   \n",
              "3649              3.2             1.0  ...                -2.7   \n",
              "3650              4.5             2.4  ...                -9.5   \n",
              "3651              8.5             7.5  ...               -12.5   \n",
              "3652              6.6             4.3  ...                -9.3   \n",
              "3653              2.9            -0.2  ...                -8.8   \n",
              "\n",
              "      STOCKHOLM_temp_max  TOURS_wind_speed  TOURS_humidity  TOURS_pressure  \\\n",
              "0                    0.7               1.6            0.97          1.0275   \n",
              "1                    2.0               2.0            0.99          1.0293   \n",
              "2                    2.8               3.4            0.91          1.0267   \n",
              "3                    4.6               4.9            0.95          1.0222   \n",
              "4                    2.9               3.6            0.95          1.0209   \n",
              "...                  ...               ...             ...             ...   \n",
              "3649                 2.4               3.7            0.95          1.0011   \n",
              "3650                 0.8               5.3            0.89          0.9966   \n",
              "3651                -7.4               3.8            0.88          0.9939   \n",
              "3652                -6.5               4.2            0.88          0.9933   \n",
              "3653                -7.0               3.4            0.86          1.0040   \n",
              "\n",
              "      TOURS_global_radiation  TOURS_precipitation  TOURS_temp_mean  \\\n",
              "0                       0.25                 0.04              8.5   \n",
              "1                       0.17                 0.16              7.9   \n",
              "2                       0.27                 0.00              8.1   \n",
              "3                       0.11                 0.44              8.6   \n",
              "4                       0.39                 0.04              8.0   \n",
              "...                      ...                  ...              ...   \n",
              "3649                    0.22                 1.50              6.2   \n",
              "3650                    0.24                 0.40             10.4   \n",
              "3651                    0.24                 1.00             10.0   \n",
              "3652                    0.58                 0.02              8.5   \n",
              "3653                    0.11                 0.00              0.5   \n",
              "\n",
              "      TOURS_temp_min  TOURS_temp_max  \n",
              "0                7.2             9.8  \n",
              "1                6.6             9.2  \n",
              "2                6.6             9.6  \n",
              "3                6.4            10.8  \n",
              "4                6.4             9.5  \n",
              "...              ...             ...  \n",
              "3649             1.8            10.6  \n",
              "3650             6.2            14.5  \n",
              "3651             8.7            11.3  \n",
              "3652             6.2            10.9  \n",
              "3653            -0.7             1.8  \n",
              "\n",
              "[3654 rows x 165 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-461b4b8c-e8bc-4c35-a634-6b298e8660c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>BASEL_cloud_cover</th>\n",
              "      <th>BASEL_humidity</th>\n",
              "      <th>BASEL_pressure</th>\n",
              "      <th>BASEL_global_radiation</th>\n",
              "      <th>BASEL_precipitation</th>\n",
              "      <th>BASEL_sunshine</th>\n",
              "      <th>BASEL_temp_mean</th>\n",
              "      <th>BASEL_temp_min</th>\n",
              "      <th>...</th>\n",
              "      <th>STOCKHOLM_temp_min</th>\n",
              "      <th>STOCKHOLM_temp_max</th>\n",
              "      <th>TOURS_wind_speed</th>\n",
              "      <th>TOURS_humidity</th>\n",
              "      <th>TOURS_pressure</th>\n",
              "      <th>TOURS_global_radiation</th>\n",
              "      <th>TOURS_precipitation</th>\n",
              "      <th>TOURS_temp_mean</th>\n",
              "      <th>TOURS_temp_min</th>\n",
              "      <th>TOURS_temp_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000101</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1.0286</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.0275</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>8.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000102</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1.0318</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>2.7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.0293</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>7.9</td>\n",
              "      <td>6.6</td>\n",
              "      <td>9.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000103</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.81</td>\n",
              "      <td>1.0314</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1.0267</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.1</td>\n",
              "      <td>6.6</td>\n",
              "      <td>9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000104</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.79</td>\n",
              "      <td>1.0262</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.35</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.0222</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.44</td>\n",
              "      <td>8.6</td>\n",
              "      <td>6.4</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000105</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.0246</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.07</td>\n",
              "      <td>3.7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.0209</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.04</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3649</th>\n",
              "      <td>20091228</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1.0084</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.0011</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.50</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>10.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>20091229</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.0028</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.9966</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.40</td>\n",
              "      <td>10.4</td>\n",
              "      <td>6.2</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3651</th>\n",
              "      <td>20091230</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.9979</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.54</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>7.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-12.5</td>\n",
              "      <td>-7.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.9939</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>11.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3652</th>\n",
              "      <td>20091231</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.1</td>\n",
              "      <td>6.6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.3</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.9933</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>8.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>10.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3653</th>\n",
              "      <td>20100101</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.9965</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.8</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.0040</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3654 rows × 165 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-461b4b8c-e8bc-4c35-a634-6b298e8660c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-461b4b8c-e8bc-4c35-a634-6b298e8660c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-461b4b8c-e8bc-4c35-a634-6b298e8660c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['DATE', 'TOURS_temp_max', 'TOURS_temp_min', 'TOURS_temp_mean']\n",
        "data = data[features]"
      ],
      "metadata": {
        "id": "c2i5HVID3xk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[:, 'DATE'] = pd.to_datetime(data.loc[:, 'DATE'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ze5nsEV_b2C",
        "outputId": "1877fbec-b0a7-4cda-c10f-864772a519d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-e88ac2bc207b>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.loc[:, 'DATE'] = pd.to_datetime(data.loc[:, 'DATE'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jZM8DvB_6xP5",
        "outputId": "e2dde04e-ed68-4ad3-bcb3-2b113739774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              DATE  TOURS_temp_max  TOURS_temp_min  \\\n",
              "0    1970-01-01 00:00:00.020000101             9.8             7.2   \n",
              "1    1970-01-01 00:00:00.020000102             9.2             6.6   \n",
              "2    1970-01-01 00:00:00.020000103             9.6             6.6   \n",
              "3    1970-01-01 00:00:00.020000104            10.8             6.4   \n",
              "4    1970-01-01 00:00:00.020000105             9.5             6.4   \n",
              "...                            ...             ...             ...   \n",
              "3649 1970-01-01 00:00:00.020091228            10.6             1.8   \n",
              "3650 1970-01-01 00:00:00.020091229            14.5             6.2   \n",
              "3651 1970-01-01 00:00:00.020091230            11.3             8.7   \n",
              "3652 1970-01-01 00:00:00.020091231            10.9             6.2   \n",
              "3653 1970-01-01 00:00:00.020100101             1.8            -0.7   \n",
              "\n",
              "      TOURS_temp_mean  \n",
              "0                 8.5  \n",
              "1                 7.9  \n",
              "2                 8.1  \n",
              "3                 8.6  \n",
              "4                 8.0  \n",
              "...               ...  \n",
              "3649              6.2  \n",
              "3650             10.4  \n",
              "3651             10.0  \n",
              "3652              8.5  \n",
              "3653              0.5  \n",
              "\n",
              "[3654 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24d3f8b1-078e-4517-ba48-39046fb77b77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>TOURS_temp_max</th>\n",
              "      <th>TOURS_temp_min</th>\n",
              "      <th>TOURS_temp_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1970-01-01 00:00:00.020000101</td>\n",
              "      <td>9.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1970-01-01 00:00:00.020000102</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1970-01-01 00:00:00.020000103</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1970-01-01 00:00:00.020000104</td>\n",
              "      <td>10.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>8.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1970-01-01 00:00:00.020000105</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6.4</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3649</th>\n",
              "      <td>1970-01-01 00:00:00.020091228</td>\n",
              "      <td>10.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>1970-01-01 00:00:00.020091229</td>\n",
              "      <td>14.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3651</th>\n",
              "      <td>1970-01-01 00:00:00.020091230</td>\n",
              "      <td>11.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3652</th>\n",
              "      <td>1970-01-01 00:00:00.020091231</td>\n",
              "      <td>10.9</td>\n",
              "      <td>6.2</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3653</th>\n",
              "      <td>1970-01-01 00:00:00.020100101</td>\n",
              "      <td>1.8</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3654 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24d3f8b1-078e-4517-ba48-39046fb77b77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24d3f8b1-078e-4517-ba48-39046fb77b77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24d3f8b1-078e-4517-ba48-39046fb77b77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = data[(data['DATE'] >= '1970-01-01 00:00:00.020000101') & (data['DATE'] < '1970-01-01 00:00:00.020080101')]\n",
        "val_set = data[(data['DATE'] >= '1970-01-01 00:00:00.020080101') & (data['DATE'] < '1970-01-01 00:00:00.020100101')]\n"
      ],
      "metadata": {
        "id": "DzrK1XFX3xrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['TOURS_temp_min'\t,'TOURS_temp_mean']\n",
        "target = 'TOURS_temp_max'\n"
      ],
      "metadata": {
        "id": "VGcLVYlAWvWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_set[features].values\n",
        "y_train = train_set[target].values\n",
        "\n",
        "X_val = val_set[features].values\n",
        "y_val = val_set[target].values\n"
      ],
      "metadata": {
        "id": "PcHHc8RRW3sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXacAoeHXchV",
        "outputId": "b5adddca-376e-4b8a-ae1a-ab298e91744f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2922, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "c7qLBJm85qOa",
        "outputId": "e66b2b3c-2769-4b61-b3e0-5cb27f0eea10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              DATE  TOURS_temp_max  TOURS_temp_min  \\\n",
              "0    1970-01-01 00:00:00.020000101             9.8             7.2   \n",
              "1    1970-01-01 00:00:00.020000102             9.2             6.6   \n",
              "2    1970-01-01 00:00:00.020000103             9.6             6.6   \n",
              "3    1970-01-01 00:00:00.020000104            10.8             6.4   \n",
              "4    1970-01-01 00:00:00.020000105             9.5             6.4   \n",
              "...                            ...             ...             ...   \n",
              "2917 1970-01-01 00:00:00.020071227             8.8             3.7   \n",
              "2918 1970-01-01 00:00:00.020071228             6.8             3.5   \n",
              "2919 1970-01-01 00:00:00.020071229             9.3             2.9   \n",
              "2920 1970-01-01 00:00:00.020071230             4.5             1.1   \n",
              "2921 1970-01-01 00:00:00.020071231             6.1             2.3   \n",
              "\n",
              "      TOURS_temp_mean  \n",
              "0                 8.5  \n",
              "1                 7.9  \n",
              "2                 8.1  \n",
              "3                 8.6  \n",
              "4                 8.0  \n",
              "...               ...  \n",
              "2917              6.2  \n",
              "2918              5.2  \n",
              "2919              6.1  \n",
              "2920              2.8  \n",
              "2921              4.2  \n",
              "\n",
              "[2922 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f5153e9-1813-48e1-be05-16bc004a569a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>TOURS_temp_max</th>\n",
              "      <th>TOURS_temp_min</th>\n",
              "      <th>TOURS_temp_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1970-01-01 00:00:00.020000101</td>\n",
              "      <td>9.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1970-01-01 00:00:00.020000102</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1970-01-01 00:00:00.020000103</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6.6</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1970-01-01 00:00:00.020000104</td>\n",
              "      <td>10.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>8.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1970-01-01 00:00:00.020000105</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6.4</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2917</th>\n",
              "      <td>1970-01-01 00:00:00.020071227</td>\n",
              "      <td>8.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2918</th>\n",
              "      <td>1970-01-01 00:00:00.020071228</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2919</th>\n",
              "      <td>1970-01-01 00:00:00.020071229</td>\n",
              "      <td>9.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2920</th>\n",
              "      <td>1970-01-01 00:00:00.020071230</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2921</th>\n",
              "      <td>1970-01-01 00:00:00.020071231</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2922 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f5153e9-1813-48e1-be05-16bc004a569a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f5153e9-1813-48e1-be05-16bc004a569a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f5153e9-1813-48e1-be05-16bc004a569a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lC8eqtqt50Vv",
        "outputId": "50ac86ec-8464-492f-f0db-6a5e10e8feb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              DATE  TOURS_temp_max  TOURS_temp_min  \\\n",
              "2922 1970-01-01 00:00:00.020080101             4.5             0.9   \n",
              "2923 1970-01-01 00:00:00.020080102             3.8            -1.1   \n",
              "2924 1970-01-01 00:00:00.020080103             7.1             0.2   \n",
              "2925 1970-01-01 00:00:00.020080104            10.0             6.0   \n",
              "2926 1970-01-01 00:00:00.020080105            10.9             8.0   \n",
              "...                            ...             ...             ...   \n",
              "3648 1970-01-01 00:00:00.020091227             9.7            -0.5   \n",
              "3649 1970-01-01 00:00:00.020091228            10.6             1.8   \n",
              "3650 1970-01-01 00:00:00.020091229            14.5             6.2   \n",
              "3651 1970-01-01 00:00:00.020091230            11.3             8.7   \n",
              "3652 1970-01-01 00:00:00.020091231            10.9             6.2   \n",
              "\n",
              "      TOURS_temp_mean  \n",
              "2922              2.7  \n",
              "2923              1.3  \n",
              "2924              3.6  \n",
              "2925              8.0  \n",
              "2926              9.4  \n",
              "...               ...  \n",
              "3648              4.6  \n",
              "3649              6.2  \n",
              "3650             10.4  \n",
              "3651             10.0  \n",
              "3652              8.5  \n",
              "\n",
              "[731 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11b82be4-b0e7-4e9c-9e98-28ff7df5ae81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>TOURS_temp_max</th>\n",
              "      <th>TOURS_temp_min</th>\n",
              "      <th>TOURS_temp_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2922</th>\n",
              "      <td>1970-01-01 00:00:00.020080101</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2923</th>\n",
              "      <td>1970-01-01 00:00:00.020080102</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2924</th>\n",
              "      <td>1970-01-01 00:00:00.020080103</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2925</th>\n",
              "      <td>1970-01-01 00:00:00.020080104</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>1970-01-01 00:00:00.020080105</td>\n",
              "      <td>10.9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>1970-01-01 00:00:00.020091227</td>\n",
              "      <td>9.7</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3649</th>\n",
              "      <td>1970-01-01 00:00:00.020091228</td>\n",
              "      <td>10.6</td>\n",
              "      <td>1.8</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3650</th>\n",
              "      <td>1970-01-01 00:00:00.020091229</td>\n",
              "      <td>14.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3651</th>\n",
              "      <td>1970-01-01 00:00:00.020091230</td>\n",
              "      <td>11.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3652</th>\n",
              "      <td>1970-01-01 00:00:00.020091231</td>\n",
              "      <td>10.9</td>\n",
              "      <td>6.2</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>731 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11b82be4-b0e7-4e9c-9e98-28ff7df5ae81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11b82be4-b0e7-4e9c-9e98-28ff7df5ae81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11b82be4-b0e7-4e9c-9e98-28ff7df5ae81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umfVNfv0WGj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your X_train and X_test data have shape (num_samples, num_features)\n",
        "timesteps = 1\n",
        "X_train = X_train.reshape(-1, timesteps, X_train.shape[1])\n",
        "y_train = y_train.reshape(-1, timesteps,1)\n",
        "X_val = X_val.reshape(-1, timesteps, X_val.shape[1])\n",
        "y_val = y_val.reshape(-1, timesteps,1)\n",
        "\n",
        "#X_test = X_test.reshape(-1, timesteps, input_dim)"
      ],
      "metadata": {
        "id": "Oav3S1OBhEx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Fc1sUTitEO",
        "outputId": "36a31e50-5764-4e7b-a0f7-e0662a714280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(731, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture for each model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(SimpleRNN(units=32, activation='tanh', input_shape=(1, 2)))\n",
        "rnn_model.add(Dense(units=1))\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(units=32, activation='tanh', input_shape=(1, 2)))\n",
        "gru_model.add(Dense(units=1))\n",
        "gru_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(units=32, activation='tanh', input_shape=(1, 2)))\n",
        "lstm_model.add(Dense(units=1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train each model with early stopping\n",
        "es_callback = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n",
        "\n",
        "rnn_history = rnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "gru_history = gru_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "lstm_history = lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "\n",
        "# Try three different step sizes for each model and compare their loss\n",
        "step_sizes = [0.1, 1, 10]\n",
        "\n",
        "for step_size in step_sizes:\n",
        "    X_train_step = np.cumsum(X_train, axis=1) * step_size\n",
        "    X_val_step = np.cumsum(X_val, axis=1) * step_size\n",
        "    \n",
        "    rnn_step_history = rnn_model.fit(X_train_step, y_train, validation_data=(X_val_step, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "    gru_step_history = gru_model.fit(X_train_step, y_train, validation_data=(X_val_step, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "    lstm_step_history = lstm_model.fit(X_train_step, y_train, validation_data=(X_val_step, y_val), epochs=100, batch_size=32, callbacks=[es_callback])\n",
        "    \n",
        "    print(f'Step size: {step_size}')\n",
        "    print(f'RNN validation loss: {rnn_step_history.history[\"val_loss\"][-1]}')\n",
        "    print(f'GRU validation loss: {gru_step_history.history[\"val_loss\"][-1]}')\n",
        "    print(f'LSTM validation loss: {lstm_step_history.history[\"val_loss\"][-1]}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ksBn3OogQiw",
        "outputId": "2f59fb2b-6853-4f8a-892c-871271f8ee22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 2s 6ms/step - loss: 322.3556 - val_loss: 231.8502\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 182.9454 - val_loss: 134.0833\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 117.0878 - val_loss: 85.3240\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78.9667 - val_loss: 62.2649\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 59.9495 - val_loss: 47.3276\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 47.2780 - val_loss: 37.3459\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 38.4224 - val_loss: 30.2502\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 31.7337 - val_loss: 24.7597\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 26.2862 - val_loss: 20.0695\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 21.7313 - val_loss: 16.3831\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 18.1072 - val_loss: 13.4538\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 15.2336 - val_loss: 11.1899\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 12.9784 - val_loss: 9.4990\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 11.1896 - val_loss: 8.1089\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 9.7924 - val_loss: 7.0398\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 8.6501 - val_loss: 6.2232\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 7.7433 - val_loss: 5.5259\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.9737 - val_loss: 4.9659\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.3084 - val_loss: 4.4980\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.7438 - val_loss: 4.0472\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.2461 - val_loss: 3.7058\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.7525 - val_loss: 3.3121\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 4.3701 - val_loss: 3.0073\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.0052 - val_loss: 2.7563\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.6839 - val_loss: 2.5856\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.4133 - val_loss: 2.2896\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.1315 - val_loss: 2.0873\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.8731 - val_loss: 1.9642\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.6522 - val_loss: 1.8887\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.4630 - val_loss: 1.6924\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.2964 - val_loss: 1.5348\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.0966 - val_loss: 1.4994\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.9480 - val_loss: 1.2361\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.7863 - val_loss: 1.1270\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.6425 - val_loss: 1.0407\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.5268 - val_loss: 1.0087\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.4117 - val_loss: 0.9951\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.3153 - val_loss: 0.7900\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.1998 - val_loss: 0.7192\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0945 - val_loss: 0.6872\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0172 - val_loss: 0.6270\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.5450\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.8588 - val_loss: 0.5562\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.8065 - val_loss: 0.5339\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.7481 - val_loss: 0.4256\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6731 - val_loss: 0.3790\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6293 - val_loss: 0.3459\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5905 - val_loss: 0.3571\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5285 - val_loss: 0.2909\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4963 - val_loss: 0.2648\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4579 - val_loss: 0.2662\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4252 - val_loss: 0.2257\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3989 - val_loss: 0.2050\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3658 - val_loss: 0.1978\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3336 - val_loss: 0.1687\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.1563\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2844 - val_loss: 0.1918\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2744 - val_loss: 0.1288\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2559 - val_loss: 0.1417\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2332 - val_loss: 0.1634\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2237 - val_loss: 0.1396\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1998 - val_loss: 0.0924\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1875 - val_loss: 0.1024\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.1020\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1697 - val_loss: 0.0732\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.0947\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1454 - val_loss: 0.0769\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1354 - val_loss: 0.0670\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.1272 - val_loss: 0.0694\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1173 - val_loss: 0.0541\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1111 - val_loss: 0.0496\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.0459\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.0433\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.0435\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0386\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.0387\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.0330\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0332\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0302\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0683\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0361\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0614 - val_loss: 0.0246\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0573 - val_loss: 0.0361\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0232\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0218\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0223\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0211\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0279\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0304\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0201\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0196\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0172\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0196\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0159\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0262\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0254\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0127\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0150\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0204\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0229\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 4s 13ms/step - loss: 266.8709 - val_loss: 190.2862\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 153.7933 - val_loss: 112.3176\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 92.0527 - val_loss: 63.6716\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 56.9479 - val_loss: 41.7828\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 40.2361 - val_loss: 29.6036\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 29.0147 - val_loss: 20.7912\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 21.3541 - val_loss: 15.2464\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 16.2631 - val_loss: 11.3714\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 12.5858 - val_loss: 8.6028\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 9.8769 - val_loss: 6.7429\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 7.9939 - val_loss: 5.2911\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.6097 - val_loss: 4.3305\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.5956 - val_loss: 3.5998\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.7878 - val_loss: 3.0852\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 4.1083 - val_loss: 2.5327\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 3.5497 - val_loss: 2.1468\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.0694 - val_loss: 1.8003\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.6713 - val_loss: 1.5262\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.3288 - val_loss: 1.2971\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.0308 - val_loss: 1.1047\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.7786 - val_loss: 0.9487\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.5614 - val_loss: 0.8016\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.3697 - val_loss: 0.6908\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.2153 - val_loss: 0.6361\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0700 - val_loss: 0.5066\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9490 - val_loss: 0.4458\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8410 - val_loss: 0.3787\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.7503 - val_loss: 0.3242\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6685 - val_loss: 0.2852\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5978 - val_loss: 0.2464\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 0.2155\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4832 - val_loss: 0.1895\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4376 - val_loss: 0.1742\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3981 - val_loss: 0.1480\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.3639 - val_loss: 0.1278\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.3313 - val_loss: 0.1158\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.3027 - val_loss: 0.1161\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.2769 - val_loss: 0.0901\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.2589 - val_loss: 0.0802\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.2345 - val_loss: 0.0742\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2180 - val_loss: 0.0684\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2014 - val_loss: 0.0693\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1878 - val_loss: 0.0542\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.0527\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 0.0436\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1502 - val_loss: 0.0395\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1396 - val_loss: 0.0373\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1304 - val_loss: 0.0340\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1223 - val_loss: 0.0301\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.0284\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.0303\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 0.0254\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.0223\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0900 - val_loss: 0.0233\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0201\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.0204\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0199\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0692 - val_loss: 0.0149\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0228\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0167\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.0135\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0546 - val_loss: 0.0136\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0135\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0107\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0121\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0098\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0419 - val_loss: 0.0115\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0095\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.0145\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0354 - val_loss: 0.0136\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.0117\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0318 - val_loss: 0.0082\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0310 - val_loss: 0.0107\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.0299 - val_loss: 0.0080\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.0272 - val_loss: 0.0075\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0103\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0100\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0109\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.0067\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0069\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.0117\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0062\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0076\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0082\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0068\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0082\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0105\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0090\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0064\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0060\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0069\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0085\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0069\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0122\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0111\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0081\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0074\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0089\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0081\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0057\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 4s 9ms/step - loss: 302.1062 - val_loss: 246.6223\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 217.1441 - val_loss: 173.2109\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 143.6704 - val_loss: 102.8286\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 86.0236 - val_loss: 60.9251\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 56.2777 - val_loss: 42.8708\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 42.5902 - val_loss: 33.0033\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 34.0116 - val_loss: 26.2241\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 27.5907 - val_loss: 20.9824\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 22.4465 - val_loss: 16.8076\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 18.2882 - val_loss: 13.4090\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 15.0049 - val_loss: 10.8292\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 12.4944 - val_loss: 8.8997\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 10.5636 - val_loss: 7.4491\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 9.1112 - val_loss: 6.3495\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 7.9641 - val_loss: 5.5233\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 7.0386 - val_loss: 4.8195\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.2702 - val_loss: 4.2713\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.5956 - val_loss: 3.7821\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.0149 - val_loss: 3.3276\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 4.5051 - val_loss: 2.9477\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.0678 - val_loss: 2.6358\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.6569 - val_loss: 2.3211\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 3.2946 - val_loss: 2.0644\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.9714 - val_loss: 1.8186\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.6792 - val_loss: 1.6217\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.4132 - val_loss: 1.4202\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2.1802 - val_loss: 1.2560\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.9536 - val_loss: 1.1102\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.7669 - val_loss: 0.9843\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.6037 - val_loss: 0.8858\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.4510 - val_loss: 0.7919\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.3178 - val_loss: 0.7198\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.1997 - val_loss: 0.6319\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.1027 - val_loss: 0.5640\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.0040 - val_loss: 0.5085\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.4647\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8389 - val_loss: 0.4260\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7769 - val_loss: 0.4051\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.7128 - val_loss: 0.3456\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6603 - val_loss: 0.3209\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 0.2814\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5606 - val_loss: 0.2874\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5154 - val_loss: 0.2383\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4782 - val_loss: 0.2245\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4461 - val_loss: 0.2122\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4121 - val_loss: 0.1886\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3852 - val_loss: 0.1762\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3616 - val_loss: 0.1468\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3324 - val_loss: 0.1419\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3077 - val_loss: 0.1223\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2902 - val_loss: 0.1135\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2658 - val_loss: 0.1156\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2534 - val_loss: 0.0996\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2328 - val_loss: 0.0917\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2265 - val_loss: 0.0870\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2053 - val_loss: 0.0750\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1972 - val_loss: 0.0738\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1783 - val_loss: 0.0679\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1726 - val_loss: 0.0711\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1590 - val_loss: 0.0546\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.0600\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1422 - val_loss: 0.0570\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1326 - val_loss: 0.0584\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1263 - val_loss: 0.0433\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1231 - val_loss: 0.0631\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1126 - val_loss: 0.0470\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1064 - val_loss: 0.0314\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0982 - val_loss: 0.0356\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0920 - val_loss: 0.0338\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0888 - val_loss: 0.0480\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0870 - val_loss: 0.0242\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0301\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0739 - val_loss: 0.0235\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0239\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0227\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0190\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0185\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0236\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.0173\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.0269\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0165\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0471 - val_loss: 0.0253\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0189\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0453 - val_loss: 0.0127\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0158\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0434 - val_loss: 0.0244\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0149\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0122\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0112\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0179\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0201\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.0170\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0093\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0159\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0107\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0165\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0097\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0241 - val_loss: 0.0108\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0139\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0122\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 48.9571 - val_loss: 10.2746\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 10.1064 - val_loss: 7.4977\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 7.7784 - val_loss: 6.2813\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.7076 - val_loss: 5.6373\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.1404 - val_loss: 5.3005\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.7313 - val_loss: 4.9583\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.3832 - val_loss: 4.6515\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.0285 - val_loss: 4.3548\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 4.6816 - val_loss: 4.0168\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 4.3425 - val_loss: 3.6950\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 3.9871 - val_loss: 3.3701\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 3.6454 - val_loss: 3.0993\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 3.2982 - val_loss: 2.7758\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.9613 - val_loss: 2.4706\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.6351 - val_loss: 2.1641\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.3198 - val_loss: 1.8784\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.0144 - val_loss: 1.6132\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.7362 - val_loss: 1.3691\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.4706 - val_loss: 1.1451\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.2352 - val_loss: 0.9488\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0220 - val_loss: 0.7845\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.8387 - val_loss: 0.6167\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6793 - val_loss: 0.4921\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5491 - val_loss: 0.4059\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.4417 - val_loss: 0.3050\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.3548 - val_loss: 0.2410\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.2874 - val_loss: 0.1920\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.2373 - val_loss: 0.1539\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1973 - val_loss: 0.1305\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1682 - val_loss: 0.1086\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 0.0953\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 0.0854\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.0776\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.0729\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.0666\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.0596\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0558\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0524\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0491\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0466\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0476\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0427\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0386\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0389\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0341\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0324\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0312\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0293\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0279\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0279\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0252\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0237\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0224\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0263\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0213\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0223\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0189\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0175\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0167\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0159\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0153\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0149\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0141\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0127\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0124\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0119\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0115\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0109\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0106\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0106\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0100\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0096\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0091\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0085\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0088\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0082\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0096\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0091\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0075\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0077\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0074\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0084\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0071\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0084\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0082\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0065\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0064\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0089\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0079\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0071\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0073\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0065\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 45.9623 - val_loss: 10.2059\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 9.9207 - val_loss: 7.2444\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 7.6483 - val_loss: 6.0990\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 6.6148 - val_loss: 5.4719\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.9786 - val_loss: 5.0016\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.4036 - val_loss: 4.5262\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.8199 - val_loss: 4.0010\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.2332 - val_loss: 3.4678\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.6800 - val_loss: 3.0137\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.1549 - val_loss: 2.5750\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.6591 - val_loss: 2.0890\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2.1977 - val_loss: 1.7402\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.7806 - val_loss: 1.3772\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.4351 - val_loss: 1.1296\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.1226 - val_loss: 0.8267\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.8683 - val_loss: 0.6256\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.6618 - val_loss: 0.4664\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4978 - val_loss: 0.3497\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3806 - val_loss: 0.2584\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2889 - val_loss: 0.1914\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2257 - val_loss: 0.1525\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1803 - val_loss: 0.1193\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1496 - val_loss: 0.1002\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1297 - val_loss: 0.0911\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1166 - val_loss: 0.0798\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1061 - val_loss: 0.0766\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0992 - val_loss: 0.0714\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0956 - val_loss: 0.0698\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0901 - val_loss: 0.0659\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0872 - val_loss: 0.0686\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0847 - val_loss: 0.0698\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0602\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0676\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.0589\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0748 - val_loss: 0.0549\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0737 - val_loss: 0.0549\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0539\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0694 - val_loss: 0.0538\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0673 - val_loss: 0.0503\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.0515\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0496\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0486\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0607 - val_loss: 0.0485\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.0455\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0590 - val_loss: 0.0466\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.0440\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0406\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0526 - val_loss: 0.0470\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0512 - val_loss: 0.0393\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0492 - val_loss: 0.0370\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0376\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0465 - val_loss: 0.0401\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0445 - val_loss: 0.0354\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0357\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0316\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.0309\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0287\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.0292\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0352 - val_loss: 0.0276\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.0255\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0282\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0265\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0222\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0239\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0250\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0189\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0189\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0208\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0173\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0178\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0147\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0175\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0135\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0127\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0125\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0123\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0128\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0104\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0121\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0116\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0094\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0121 - val_loss: 0.0156\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0103\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0122\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0118\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0081\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0078\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0092\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0085\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0127\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0071\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0076\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0070\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0068\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0078\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0066\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0068\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 64.1468 - val_loss: 8.9496\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 9.4282 - val_loss: 7.3639\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 8.2888 - val_loss: 6.6062\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 7.4665 - val_loss: 6.0175\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 6.8043 - val_loss: 5.5381\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 6.2260 - val_loss: 5.1280\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.7139 - val_loss: 4.7147\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.2096 - val_loss: 4.3047\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 4.7084 - val_loss: 3.8980\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 4.1911 - val_loss: 3.4368\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 3.6634 - val_loss: 2.9657\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 3.1559 - val_loss: 2.5346\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2.6830 - val_loss: 2.1457\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2.2406 - val_loss: 1.7517\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.8305 - val_loss: 1.4271\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.4760 - val_loss: 1.1249\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1775 - val_loss: 0.8921\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9397 - val_loss: 0.7025\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7447 - val_loss: 0.5609\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5966 - val_loss: 0.4449\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.4891 - val_loss: 0.3653\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.4072 - val_loss: 0.3096\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3505 - val_loss: 0.2702\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3097 - val_loss: 0.2412\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2794 - val_loss: 0.2242\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2575 - val_loss: 0.2077\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2411 - val_loss: 0.1972\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 0.1851\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2164 - val_loss: 0.1754\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.1668\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1981 - val_loss: 0.1681\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1896 - val_loss: 0.1568\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1832 - val_loss: 0.1462\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1768 - val_loss: 0.1448\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1718 - val_loss: 0.1371\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1654 - val_loss: 0.1332\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1303\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1536 - val_loss: 0.1242\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1501 - val_loss: 0.1244\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1437 - val_loss: 0.1143\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1385 - val_loss: 0.1103\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1330 - val_loss: 0.1050\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1281 - val_loss: 0.1015\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1248 - val_loss: 0.0976\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1185 - val_loss: 0.0974\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1137 - val_loss: 0.0897\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.1088 - val_loss: 0.0859\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1036 - val_loss: 0.0837\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.0775\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0950 - val_loss: 0.0729\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.0705\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0854 - val_loss: 0.0682\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0825 - val_loss: 0.0632\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0761 - val_loss: 0.0594\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0571\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.0519\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0637 - val_loss: 0.0492\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0596 - val_loss: 0.0446\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0562 - val_loss: 0.0414\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0522 - val_loss: 0.0417\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0502 - val_loss: 0.0362\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0458 - val_loss: 0.0363\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.0313\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0298\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0272\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0244\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0247\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0231\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0196\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0184\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0175\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0162\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0157\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0148\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0151\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0141\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0131\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0121\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0121\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0110\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0108\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0107\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0098\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0096\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0094\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0100\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0096\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0088\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0087\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0085\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0091\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0082\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0094\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0082\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0080\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0087\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0077\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0075\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0078\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0076\n",
            "Step size: 0.1\n",
            "RNN validation loss: 0.006539203692227602\n",
            "GRU validation loss: 0.006803836207836866\n",
            "LSTM validation loss: 0.007561872713267803\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 425.8021 - val_loss: 47.4292\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 23.9673 - val_loss: 15.7289\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 13.6587 - val_loss: 11.2504\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 10.7829 - val_loss: 9.1619\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 9.1979 - val_loss: 7.7686\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 8.1702 - val_loss: 6.8671\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 7.3886 - val_loss: 6.1161\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 6.6768 - val_loss: 5.3938\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.8365 - val_loss: 4.4408\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.0583 - val_loss: 3.9823\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 4.6558 - val_loss: 3.6515\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.3453 - val_loss: 3.4087\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 4.0698 - val_loss: 3.1984\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.8152 - val_loss: 2.9489\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.5857 - val_loss: 2.7659\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 3.3776 - val_loss: 2.5991\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.1673 - val_loss: 2.4283\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.9820 - val_loss: 2.2515\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.8035 - val_loss: 2.1179\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.6401 - val_loss: 1.9600\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.4750 - val_loss: 1.8622\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.3294 - val_loss: 1.7069\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.1860 - val_loss: 1.6056\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.0371 - val_loss: 1.4651\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.9229 - val_loss: 1.4037\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.7653 - val_loss: 1.2642\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.6390 - val_loss: 1.1327\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.5109 - val_loss: 1.0290\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.3762 - val_loss: 0.9226\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.2571 - val_loss: 0.8815\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.1398 - val_loss: 0.7298\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0341 - val_loss: 0.6375\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.9306 - val_loss: 0.6094\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.8480 - val_loss: 0.4969\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7747 - val_loss: 0.4426\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.7198 - val_loss: 0.4037\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6638 - val_loss: 0.3723\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.3568\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5657 - val_loss: 0.3285\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5256 - val_loss: 0.2856\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4956 - val_loss: 0.2601\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4599 - val_loss: 0.2730\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4326 - val_loss: 0.2482\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4074 - val_loss: 0.2209\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3806 - val_loss: 0.2061\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3579 - val_loss: 0.2167\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3362 - val_loss: 0.1921\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3160 - val_loss: 0.1703\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2992 - val_loss: 0.1582\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2833 - val_loss: 0.1536\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.2680 - val_loss: 0.1612\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2516 - val_loss: 0.1479\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.2357 - val_loss: 0.1448\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.2245 - val_loss: 0.1419\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.2100 - val_loss: 0.1076\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.1992 - val_loss: 0.1009\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.0963\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1803 - val_loss: 0.0885\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1683 - val_loss: 0.0840\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1602 - val_loss: 0.0777\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1503 - val_loss: 0.0827\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.1471 - val_loss: 0.0701\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.1370 - val_loss: 0.0722\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.1299 - val_loss: 0.0639\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 0.0633\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.0541\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1127 - val_loss: 0.0555\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1096 - val_loss: 0.0654\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.0492\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0536\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.0403\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0384\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0368\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0400\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0323\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0310\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0333\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0321\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0248\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0570 - val_loss: 0.0242\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0581 - val_loss: 0.0277\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0520 - val_loss: 0.0275\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0203\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0472 - val_loss: 0.0230\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0180\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0167\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.0198\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.0151\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0175\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0197\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0138\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0130\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0137\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0123\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0215\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0103\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0128\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0104\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0107\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0144\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 331.6373 - val_loss: 12.9038\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 8.0441 - val_loss: 4.9324\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.5856 - val_loss: 3.5956\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.2520 - val_loss: 2.3690\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.4411 - val_loss: 1.9328\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.0982 - val_loss: 1.6472\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.8567 - val_loss: 1.4415\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.6709 - val_loss: 1.2588\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.5289 - val_loss: 1.1387\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.4118 - val_loss: 1.0413\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 1.2988 - val_loss: 0.9507\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 1.2110 - val_loss: 0.8760\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.1011 - val_loss: 0.8396\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.9880 - val_loss: 0.6707\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.9221 - val_loss: 0.6349\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.8616 - val_loss: 0.5928\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8320 - val_loss: 0.5613\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7722 - val_loss: 0.5153\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7271 - val_loss: 0.5171\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6856 - val_loss: 0.4440\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6504 - val_loss: 0.4312\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6083 - val_loss: 0.3792\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5261 - val_loss: 0.2881\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3557 - val_loss: 0.2036\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2759 - val_loss: 0.1846\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2503 - val_loss: 0.1703\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2306 - val_loss: 0.1453\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.1435\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1946 - val_loss: 0.1213\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1773 - val_loss: 0.1069\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1578 - val_loss: 0.1006\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1343 - val_loss: 0.0859\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1165 - val_loss: 0.0770\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1034 - val_loss: 0.0716\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0962 - val_loss: 0.0649\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0886 - val_loss: 0.0585\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0531\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0780 - val_loss: 0.0494\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0728 - val_loss: 0.0480\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0690 - val_loss: 0.0433\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0641 - val_loss: 0.0434\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0591 - val_loss: 0.0368\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0561 - val_loss: 0.0386\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0523 - val_loss: 0.0317\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0493 - val_loss: 0.0303\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0464 - val_loss: 0.0300\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0471 - val_loss: 0.0319\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0242\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0389 - val_loss: 0.0235\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0223\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0356 - val_loss: 0.0313\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0340 - val_loss: 0.0221\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0229\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.0197\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0171\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0183\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0193\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0159\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0158\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0150\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0191\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0152\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0144\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0154\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0137\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0137\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0165\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0141\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0168\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0131\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0128\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0178\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0136\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0131\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0135\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0118\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0115\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0112\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0122 - val_loss: 0.0107\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0103\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0125\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0116\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0124\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0147\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0099\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0120\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0143\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0108\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0104\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0110\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0104\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0204\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0104\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0118\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0111\n",
            "Epoch 96: early stopping\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 353.1461 - val_loss: 34.0915\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 9.6942 - val_loss: 3.2530\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.0160 - val_loss: 2.1847\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.1808 - val_loss: 1.5867\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.7274 - val_loss: 1.3374\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.5270 - val_loss: 1.2383\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.3970 - val_loss: 1.0853\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.2918 - val_loss: 0.9976\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1974 - val_loss: 0.9222\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1193 - val_loss: 0.8552\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 1.0646 - val_loss: 0.8351\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 1.0028 - val_loss: 0.7638\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.9565 - val_loss: 0.7123\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.9035 - val_loss: 0.7065\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.8767 - val_loss: 0.6368\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.8313 - val_loss: 0.6066\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.7866 - val_loss: 0.6215\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.7605 - val_loss: 0.5443\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.7259 - val_loss: 0.5497\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6937 - val_loss: 0.5085\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5641 - val_loss: 0.2990\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3569 - val_loss: 0.2032\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2744 - val_loss: 0.1815\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2508 - val_loss: 0.1586\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2317 - val_loss: 0.1446\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2036 - val_loss: 0.1430\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1808 - val_loss: 0.1211\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1572 - val_loss: 0.1114\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1455 - val_loss: 0.1029\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1379 - val_loss: 0.1040\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1298 - val_loss: 0.0944\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1266 - val_loss: 0.1038\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1169 - val_loss: 0.0822\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1160 - val_loss: 0.0853\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1054 - val_loss: 0.0776\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1036 - val_loss: 0.0735\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.0732\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0968 - val_loss: 0.0659\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0899 - val_loss: 0.0669\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0898 - val_loss: 0.0625\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0874 - val_loss: 0.0562\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0634\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0606\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0517\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0759 - val_loss: 0.0520\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0735 - val_loss: 0.0496\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0719 - val_loss: 0.0511\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0710 - val_loss: 0.0449\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0685 - val_loss: 0.0428\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0654 - val_loss: 0.0431\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0630 - val_loss: 0.0410\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0623 - val_loss: 0.0486\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0602 - val_loss: 0.0344\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0583 - val_loss: 0.0373\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0554 - val_loss: 0.0353\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0547 - val_loss: 0.0328\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0377\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.0314\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.0375\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0455 - val_loss: 0.0303\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0277\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0274\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0253\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0255\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0246\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0391 - val_loss: 0.0225\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0366 - val_loss: 0.0230\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0385 - val_loss: 0.0232\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0260\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0240\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.0214\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0320 - val_loss: 0.0243\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0228\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0308 - val_loss: 0.0176\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0295 - val_loss: 0.0188\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0162\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0158\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0163\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0218\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0145\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0156\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0164\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0153\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0185\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0263\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0132\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0163\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0185\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0125\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0142\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0150\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0141\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0112\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0128\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0112\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0146\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0100\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0103\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0099\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0159\n",
            "Step size: 1\n",
            "RNN validation loss: 0.014364032074809074\n",
            "GRU validation loss: 0.011149673722684383\n",
            "LSTM validation loss: 0.015861866995692253\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 74.0222 - val_loss: 8.9578\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 8.6694 - val_loss: 4.7793\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 5.5658 - val_loss: 3.3133\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 4.2332 - val_loss: 2.3607\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.4799 - val_loss: 1.9968\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.8857 - val_loss: 1.5554\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2.3456 - val_loss: 1.2899\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.9817 - val_loss: 1.0664\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.7751 - val_loss: 1.0016\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.5180 - val_loss: 0.8031\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.3136 - val_loss: 0.7403\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.2258 - val_loss: 0.6360\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.1075 - val_loss: 0.6348\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1.0360 - val_loss: 0.5219\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.9737 - val_loss: 0.4863\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8734 - val_loss: 0.4557\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8205 - val_loss: 0.6101\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8095 - val_loss: 0.5057\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.7509 - val_loss: 0.4266\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7075 - val_loss: 0.4081\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6665 - val_loss: 0.3618\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6436 - val_loss: 0.3761\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6064 - val_loss: 0.3527\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6063 - val_loss: 0.3955\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5787 - val_loss: 0.3411\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5505 - val_loss: 0.2900\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5173 - val_loss: 0.2945\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.5065 - val_loss: 0.2819\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4745 - val_loss: 0.3047\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4440 - val_loss: 0.3737\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4315 - val_loss: 0.2733\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.4137 - val_loss: 0.3066\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.4079 - val_loss: 0.2425\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3963 - val_loss: 0.2693\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3643 - val_loss: 0.2156\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3801 - val_loss: 0.2174\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3273 - val_loss: 0.1873\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3316 - val_loss: 0.3099\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.3188 - val_loss: 0.1742\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2921 - val_loss: 0.3104\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.1650\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2727 - val_loss: 0.1567\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2607 - val_loss: 0.1280\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2320 - val_loss: 0.1940\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2516 - val_loss: 0.5052\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2282 - val_loss: 0.1624\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2124 - val_loss: 0.1634\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.2240 - val_loss: 0.1492\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1909 - val_loss: 0.1095\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1776 - val_loss: 0.1238\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1799 - val_loss: 0.0899\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.2009\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.1104\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 0.1288\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.1471\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1490 - val_loss: 0.0665\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 0.1353 - val_loss: 0.1255\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1389 - val_loss: 0.0885\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1347 - val_loss: 0.1003\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.1812\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1443 - val_loss: 0.1208\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1298 - val_loss: 0.0698\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1299 - val_loss: 0.2358\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1435 - val_loss: 0.0685\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1173 - val_loss: 0.0844\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1063 - val_loss: 0.0831\n",
            "Epoch 66: early stopping\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 77.1428 - val_loss: 10.7690\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 8.5557 - val_loss: 4.2738\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.4733 - val_loss: 3.3115\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.5599 - val_loss: 2.9959\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.8550 - val_loss: 2.5944\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.3984 - val_loss: 2.2520\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.9111 - val_loss: 1.8089\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.6474 - val_loss: 1.7380\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.3399 - val_loss: 1.5070\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.1144 - val_loss: 1.2716\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.9924 - val_loss: 1.6761\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.7331 - val_loss: 1.0334\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.6086 - val_loss: 0.9359\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.4375 - val_loss: 0.8502\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.3911 - val_loss: 0.8359\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.2408 - val_loss: 0.8379\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1704 - val_loss: 0.8652\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1201 - val_loss: 0.7115\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.0174 - val_loss: 0.6286\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9274 - val_loss: 0.6164\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9013 - val_loss: 0.5892\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8154 - val_loss: 0.4955\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7512 - val_loss: 0.4484\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6991 - val_loss: 0.4852\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6623 - val_loss: 0.4046\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.6322 - val_loss: 0.4997\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.5832 - val_loss: 0.3848\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.5766 - val_loss: 0.5154\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.5256 - val_loss: 0.3305\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.5190 - val_loss: 0.2826\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.4924 - val_loss: 0.5707\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4633 - val_loss: 0.2825\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4268 - val_loss: 0.2781\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4120 - val_loss: 0.2602\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.3787 - val_loss: 0.2522\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.3782 - val_loss: 0.2162\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3291 - val_loss: 0.2085\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3361 - val_loss: 0.2317\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3225 - val_loss: 0.1917\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2994 - val_loss: 0.2746\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3372 - val_loss: 0.1878\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3136 - val_loss: 0.2727\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3085 - val_loss: 0.2190\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2822 - val_loss: 0.1518\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2399 - val_loss: 0.1636\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2561 - val_loss: 0.1691\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2647 - val_loss: 0.2419\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2338 - val_loss: 0.1280\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2220 - val_loss: 0.1228\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2183 - val_loss: 0.1419\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2105 - val_loss: 0.1790\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2013 - val_loss: 0.1121\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.1138\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2176 - val_loss: 0.1299\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1888 - val_loss: 0.1796\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1792 - val_loss: 0.1354\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1757 - val_loss: 0.0993\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1789 - val_loss: 0.1308\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1658 - val_loss: 0.1134\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.2572\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1678 - val_loss: 0.1117\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1626 - val_loss: 0.0874\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1421 - val_loss: 0.1007\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1416 - val_loss: 0.0849\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1457 - val_loss: 0.1223\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1412 - val_loss: 0.0688\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1298 - val_loss: 0.0811\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1287 - val_loss: 0.1213\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.1374 - val_loss: 0.1234\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1139 - val_loss: 0.1034\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1207 - val_loss: 0.0902\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1262 - val_loss: 0.0839\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1285 - val_loss: 0.1266\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1313 - val_loss: 0.0838\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1211 - val_loss: 0.1171\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1286 - val_loss: 0.0680\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1121 - val_loss: 0.0898\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1086 - val_loss: 0.0745\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1034 - val_loss: 0.0730\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1291 - val_loss: 0.0746\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1090 - val_loss: 0.0746\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1121 - val_loss: 0.0655\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1317 - val_loss: 0.1011\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1182 - val_loss: 0.0735\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0943 - val_loss: 0.0790\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1146 - val_loss: 0.0772\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0999 - val_loss: 0.0851\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0958 - val_loss: 0.0574\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0992 - val_loss: 0.0668\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0561\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0637\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0923 - val_loss: 0.1197\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0836 - val_loss: 0.0932\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0935 - val_loss: 0.0807\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0739 - val_loss: 0.0626\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0736\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0787 - val_loss: 0.0915\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.0467\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0684 - val_loss: 0.0443\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.0809 - val_loss: 0.0545\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 75.6331 - val_loss: 21.3579\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 23.3636 - val_loss: 19.5828\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 19.6979 - val_loss: 15.6802\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 16.2878 - val_loss: 11.3367\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 12.9506 - val_loss: 9.2257\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 10.6860 - val_loss: 7.4366\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 9.1894 - val_loss: 6.7955\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 8.1061 - val_loss: 5.5964\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 6.9155 - val_loss: 4.9490\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 6.2746 - val_loss: 4.4973\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 5.4187 - val_loss: 3.7241\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.7168 - val_loss: 3.3176\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 4.1099 - val_loss: 2.7782\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 3.6276 - val_loss: 2.4236\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 3.2208 - val_loss: 2.0251\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.7670 - val_loss: 1.7337\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.3968 - val_loss: 1.5706\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2.1705 - val_loss: 1.3254\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.9257 - val_loss: 1.3276\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.7404 - val_loss: 1.1572\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.5687 - val_loss: 0.9859\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.4508 - val_loss: 0.9126\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.3290 - val_loss: 0.7926\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.2156 - val_loss: 0.7746\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.1172 - val_loss: 0.6635\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 1.0469 - val_loss: 0.6226\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9645 - val_loss: 0.5686\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.9195 - val_loss: 0.5400\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.8403 - val_loss: 0.5294\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7908 - val_loss: 0.4509\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.7377 - val_loss: 0.4402\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6950 - val_loss: 0.4639\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6642 - val_loss: 0.4967\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.6265 - val_loss: 0.4147\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6004 - val_loss: 0.4418\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.6114 - val_loss: 0.3898\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.3164\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.5146 - val_loss: 0.3689\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.5575 - val_loss: 0.2982\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4690 - val_loss: 0.3361\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.4548 - val_loss: 0.6184\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.4283 - val_loss: 0.2223\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3894 - val_loss: 0.2145\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3708 - val_loss: 0.2142\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3826 - val_loss: 0.2028\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3240 - val_loss: 0.2128\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3641 - val_loss: 0.1647\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.3012 - val_loss: 0.1878\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2810 - val_loss: 0.1682\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2707 - val_loss: 0.2187\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2732 - val_loss: 0.1406\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.1444\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2576 - val_loss: 0.2024\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2357 - val_loss: 0.2082\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2353 - val_loss: 0.2026\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2188 - val_loss: 0.1534\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2159 - val_loss: 0.2430\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1993 - val_loss: 0.1740\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1894 - val_loss: 0.1052\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2388 - val_loss: 0.1195\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1960 - val_loss: 0.1068\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1745 - val_loss: 0.0925\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1721 - val_loss: 0.0916\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1789 - val_loss: 0.2716\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.2091 - val_loss: 0.2129\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1999 - val_loss: 0.0900\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1657 - val_loss: 0.0911\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1387 - val_loss: 0.0988\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1521 - val_loss: 0.0774\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1366 - val_loss: 0.0721\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1855 - val_loss: 0.0772\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1275 - val_loss: 0.0660\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.0983\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1303 - val_loss: 0.1279\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 0.1351 - val_loss: 0.1038\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1279 - val_loss: 0.1354\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1280 - val_loss: 0.0676\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1036 - val_loss: 0.1093\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1078 - val_loss: 0.0618\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.0575\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1118 - val_loss: 0.0575\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0914 - val_loss: 0.0508\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1086 - val_loss: 0.1447\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1069 - val_loss: 0.0580\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1036 - val_loss: 0.1703\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1175 - val_loss: 0.3202\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1030 - val_loss: 0.0546\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1378 - val_loss: 0.0899\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0927 - val_loss: 0.0934\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.1735 - val_loss: 0.0465\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0737 - val_loss: 0.0696\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0875 - val_loss: 0.0633\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0795 - val_loss: 0.0813\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.0456\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0696 - val_loss: 0.0416\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0732 - val_loss: 0.0376\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.1227\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0788 - val_loss: 0.0353\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0716 - val_loss: 0.0438\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 0.0718 - val_loss: 0.0783\n",
            "Step size: 10\n",
            "RNN validation loss: 0.0830572098493576\n",
            "GRU validation loss: 0.054498687386512756\n",
            "LSTM validation loss: 0.0783223807811737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DgQBxeGAgQgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ejb1o_JcgQeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4n71uKVKgQa4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}